# Data-Pipeline---Data-Engineering-Project
This project focuses on building a big data pipeline for analyzing Netflix content and user trends using Databricks, PySpark, SQL. The pipeline extracts data from sources and 
performs transformations in Databricks.

Databricks (Apache Spark): Managed big data platform for large-scale data processing.
✅ PySpark (Spark SQL, DataFrames): Data transformation, cleaning, and aggregation.
✅ SQL (Databricks SQL): Querying and structuring data efficiently.
✅ Delta Lake: Storage layer for ACID-compliant, optimized data management.
✅ ETL Pipeline (Databricks Jobs & Notebooks): Automating data workflows.
✅ Data Cleaning & Preprocessing: Handling missing values, standardizing dates, and normalizing text.
✅ Cloud Storage (DBFS): Storing raw and processed data.

